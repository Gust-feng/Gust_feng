# 从记事本开始

> 起步于微末之处，不惧其浅陋；
> 迭代于寸进之中，自有其峥嵘。

任何系统性的理解，都不是直接生成的终态，而是在大量局部判断的反复修正中逐步拼合而成。这些判断往往是临时的、不完整的，甚至会在之后被推翻，但正是由它们所构成的中间过程，使认知得以从不确定中逐渐走向稳定。对这些过程的记录，其意义并不在于确认当下的结论，而在于保留理解如何形成与变化的轨迹。

从这一角度看，学习并不只是信息的累积，更是一种持续调整认知结构的活动。新的输入不断改变既有判断的相对位置，引发重组、修正与取舍，使原本看似清晰的理解再次接受检验。当这些变化被保留下来，理解便不再停留于瞬时状态，而成为一个可以回顾、比较与重新建构的对象。

因此，记录并非学习之外的附属行为，而	是其中自然的一部分。它使认知的发展不必依赖记忆的偶然性，而能够在反复回溯与修订中逐步收敛。当理解被允许在时间中展开时，学习本身也随之呈现为一个持续成形的过程，而非一次性的完成。

# 尝试些不同的方向

在相邻但不完全重合的领域中不断尝试新事物，可以更清晰地识别既有理解的适用边界；当同一问题在不同背景下被反复观察时，理解往往不再依赖单一叙述，而呈现出多种可能的解释路径。这些路径之间未必彼此排斥，它们更多地构成了一种互相校正的关系，使认知结构在张力中保持弹性。正是在这种弹性之中，理解得以避免过早固化，从而为后续的成长提供发展空间。

## 模型微调

首次接触《[Titanfall](https://store.steampowered.com/app/1237970/Titanfall_2/)》时，[BT-7274的回复](支线\其他\模型微调\etc\BT-7274\index.html)让我对AI拟人化有了具象化的认识，我在思考，是否能将AI运用到这上面来，尝试打造一个现实版的BT-7274?

实际上，进行模型微调需要及其丰富且高质量风格对话的数据集作为支撑，通常认为高质量的数据集的训练效果远比混乱的数据集要好的多，但游戏内的数据的太多单一且符合要求的语料太少，想凭此训练出BT-7274太难，因此如何获得丰富的数据集成为一大难点。

> [模型微调](支线\其他\模型微调\模型微调.md)

## 桌面壁纸

我不想使用千篇一律、枯燥无味的壁纸，那只会让我反感。我见过许多真正有趣、有巧思的壁纸，它们并不依赖复杂的元素或张扬的设计，而是通过构图、色彩或某种隐含的秩序感，传达出一种相互交融却又彼此独立的美学，以较少的元素承载出更为丰富的层次与关系。

在这样的设计理念中，注意力不会被迅速牵引到某一个明确的中心，而是在不同区域之间转移，使观看本身成为一种持续而低强度的过程。正是这种不急于表达的特性，使其更适合作为长期存在的背景。

基于以上理念，并结合 wallpaper 所提供的稳定承载形式，使应用不再成为创作的掣肘，让创意重新回到画面本身的结构与关系之上。

> [wallpaper壁纸](支线\其他\HTML\wallpaper专区\使用说明.md)
> [优雅桌面](https://github.com/Gust-feng/Elegant-desktop)
> [Gust-feng](https://gust-feng.github.io/my-home/)
